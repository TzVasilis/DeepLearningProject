{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataloaders import data_loaders\n",
    "from DeepLabV3Plus_ResNet50 import Deeplabv3Plus\n",
    "from google.colab import drive\n",
    "from plot_utils import (\n",
    "    plot_training_validation_losses,\n",
    "    show_images_and_masks,\n",
    "    visualize_predictions,\n",
    ")\n",
    "from predict import make_predictions\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from train import train_and_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "!unzip -q /content/drive/MyDrive/carseg_arrays.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = \"/content/dataset\"\n",
    "pickle_file_path = \"/content/deeplabv3plus_train_metrics.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [f\"photo_{str(i).zfill(4)}.npy\" for i in range(1, 31)]\n",
    "\n",
    "test_set = [os.path.join(SOURCE_DIR, filename) for filename in test_list]\n",
    "\n",
    "replicate_list = [f\"photo_{str(i).zfill(4)}.npy\" for i in range(32, 169)]\n",
    "\n",
    "replication_factor = 2\n",
    "\n",
    "replicated_list = [\n",
    "    filename for filename in replicate_list for _ in range(replication_factor)\n",
    "]\n",
    "\n",
    "train_set = [\n",
    "    os.path.join(SOURCE_DIR, filename)\n",
    "    for filename in os.listdir(SOURCE_DIR)\n",
    "    if filename not in test_list\n",
    "]\n",
    "\n",
    "train_set += [\n",
    "    os.path.join(SOURCE_DIR, filename) for filename in replicated_list\n",
    "]\n",
    "\n",
    "train_list = [\n",
    "    filename\n",
    "    for filename in os.listdir(SOURCE_DIR)\n",
    "    if os.path.isfile(os.path.join(SOURCE_DIR, filename))\n",
    "    and filename not in test_list\n",
    "]\n",
    "\n",
    "train_list += replicated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"deeplabv3+\"\n",
    "train_loader, val_loader, test_loader = data_loaders(\n",
    "    model_type, train_set, test_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(train_loader)\n",
    "images, masks = next(data_iterator)\n",
    "show_images_and_masks(images, masks, num_samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(masks.shape[0]):\n",
    "    mask = masks[i]\n",
    "    unique_labels = np.unique(mask)\n",
    "    print(f\"Unique labels in mask {i + 1}: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 7\n",
    "T_MAX = 30\n",
    "ETA_MIN = 1e-6\n",
    "INPUT_CHANNELS = 3\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deeplabv3Plus(INPUT_CHANNELS, NUM_CLASSES)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=ETA_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_and_validate(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    NUM_CLASSES,\n",
    "    EPOCHS,\n",
    "    DEVICE,\n",
    "    PATIENCE,\n",
    "    use_scheduler=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = history[\"train_losses\"]\n",
    "val_losses = history[\"val_losses\"]\n",
    "iou_scores = history[\"iou_scores\"]\n",
    "dice_scores = history[\"dice_scores\"]\n",
    "class_iou = history[\"class_iou\"]\n",
    "class_dice = history[\"class_dice\"]\n",
    "pixel_accuracies = history[\"pixel_accuracies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "    \"iou_scores\": iou_scores,\n",
    "    \"dice_scores\": dice_scores,\n",
    "    \"class_iou\": class_iou,\n",
    "    \"class_dice\": class_dice,\n",
    "    \"pixel_accuracies\": pixel_accuracies,\n",
    "}\n",
    "\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pickle.dump(history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(val_losses) + 1)\n",
    "plot_training_validation_losses(epochs, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice_score = sum(dice_scores) / len(dice_scores)\n",
    "print(f\"Mean Dice Coefficient: {mean_dice_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_score = sum(iou_scores) / len(iou_scores)\n",
    "print(f\"Mean IoU Score: {mean_iou_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pixel_accuracy = sum(pixel_accuracies) / len(pixel_accuracies)\n",
    "print(f\"Mean Pixel Accuracy: {mean_pixel_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"deeplabv3plus_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = make_predictions(\n",
    "    model, test_loader, DEVICE, NUM_CLASSES, num_samples=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou = predictions[\"iou\"]\n",
    "mean_dice = predictions[\"dice\"]\n",
    "mean_pixel_accuracy = predictions[\"pixel_accuracy\"]\n",
    "\n",
    "print(f\"Mean IoU: {mean_iou}\")\n",
    "print(f\"Mean Dice: {mean_dice}\")\n",
    "print(f\"Mean Pixel Accuracy: {mean_pixel_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
